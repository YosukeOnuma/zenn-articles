---
title: "【初学者向け】VAEをつかむ，式変形はわからなくて良い"
emoji: "😭"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["VAE","生成AI","機械学習"]
published: false
---

## 本記事の狙い
**生成モデル初学者向け**です．VAE（Variational Auto-Encoder）の解説記事を読んでも、式変形ばかりで結局何をしてるのかよくわからない...という人に向けています
- VAEが大まかに何をするか、から解説します
- その後，ネットワーク構造、損失関数など、機械学習のよくあるアプローチで紹介します
- 変分ベイズ推定の式変形は詳しく解説しません

## VAEとは何か
画像などを生成できる，生成モデルです．大まかに以下のことをしています[^1]．
![](/images/vae-without-variational/overview.png)
一言で言えば，**入力データから本質的な潜在変数を確率分布として学習し，この分布から潜在変数をサンプリングして再生成することで，多様な出力が得られるようになります**．
この流れ自体はVAE以外にもよくある話です．VAEの特徴は，学習過程において「変分ベイズ推定」と「Re-parameterization trick」を用いることにあります．が，全体像の理解のためにはこれは後回しで良いです．
[^1]: この図の②は若干不正確です．（以下，記事の内容を理解した人向け）潜在変数分布からサンプリングした潜在変数をNNに入れると，出力されるのは顔画像そのものではなく顔画像の分布のパラメタ（平均とか分散とか）であり，つまり$p_\theta (X|z)$です．これで損失関数を計算するのですからね．ただ実用上，画像を生成する際は，この顔画像分布から再びサンプリングするのではなく，その平均値を生成結果とすることが多いらしいです．

## ネットワークの構造
VAEは下図のように，EncoderとDecoderの２つのニューラルネットワークで構成されています．先ほどの図の③がEncoder，②がDecoderですね．
![](/images/vae-without-variational/structure.png)
図中の"sample"というのは，確率分布に従って変数をランダムに生成する，ということです．
なおわかりやすさのために，図中ではDecoderが出力する$z$のパラメタは$\mu$,$\sigma$の２種類になっています．しかし実務では$\sigma$は固定値を用いたり，正規分布以外の分布を採用したりなど，様々です．

:::message
**学習が済めば，画像の生成に必要なのは，学習した潜在変数$z$のパラメタとDecoderNNだけ**です．EncoderNNは，潜在変数$z$のパラメタを得るために学習時のみ使用します．
:::

## 学習の流れ

ミニバッチごとに、以下の処理を繰り返しています．

1. **生成、そして損失計算**
    - 入力データ$X$をEncoderに通し，潜在変数$z$の分布を得る
    - $z$を得られた分布に従ってサンプリング
    - その$z$をDecoderに通して生成データ$X'$の分布を得る
    - $X'$を得られた分布に従ってサンプリング
    - 投入データ$X$と生成データ$X'$の間で損失関数（後述）を計算
2. **ネットワーク全体に誤差逆伝播**
    - この損失に対してDecoderNN，EncoderNNについて誤差逆伝播を行い
    - SGDやAdamなどで両ネットワークのパラメータを一緒に更新

「サンプリング」という確率的な操作があるのに，Encoder側まで一気に誤差逆伝播をします．いったいどうやって？というのがReparameterization trickです．後ほど説明します．

## 損失関数

- 次の値を**最大化**することを考える。**第一項が再構成項、第二項が正則化項**
    
    $$
    \text{ELBO} = \mathbb{E}_{q_\phi (z|X)}[\text{log}\,p_\theta (X|z)] - \text{KL}\bigl( q_\phi (z|X)|| p_{prior}(z) \bigr)
    $$
    
    :::message
    ここの$p_\theta (\cdot)$と$p_{prior}(\cdot )$は全くの別物。前者はデコーダNN、後者は潜在変数$z$の事前分布で標準正規分布$N(\bold0,\bold{I})$をよく使う。*両者別物の関数のくせに確率論の慣習で同じ$p$を使いやがる。なお$q$は、変分ベイズで登場する、真の分布の近似分布。*
    :::
    
- 第１項を大きくすることは、「出力の期待値が入力に近づく」こと。潜在空間からのデータ生成（デコーダ）の出力期待値を、入力データからの潜在空間推定（エンコーダ）に沿って計算してる
- 第２項のKLを小さく保つことは、「エンコーダの出力が事前分布に近づく」こと。過学習を防ぐ。
- もちろんこの２項のバランスはそう単純じゃないので、第二項に重みをつけたりする


## （余談）Auto Encoderとの違い
- Encoderでデータから潜在変数を学習し，Decoderで潜在変数からデータの再生成を試みるため，結果的にAuto Encoderの形になっています．AEは入力をそのまま再現することだけを考えますが、VAEは潜在変数$z$の分布が標準正規分布（など設定した事前分布）に近いと想定しながら、入力$X$に整合的な潜在空間$z$の**分布**を学習します


## Reparametrization trick

- ニューラルネットの中に確率過程があるため、普通の誤差逆伝播ができない。ここで、VAEの構造を以下のように解釈することで、確率過程を外に出して、誤差逆伝播を可能にした。これをreparametrization trickと言う。（そんな突飛でもねえな）
$z=μ_ϕ(X)+σ_ϕ(X)ϵ \; (\,ϵ∼N(0,I)\,)$ をサンプリング（後述のreparametrization）

## 損失関数の導出 - 変分ベイズ推定の部分

## 終わりに
VAEは実際のところ、変分ベイズ推定による潜在変数$z$の推定から誕生した手法です。ですがここまで見てきたように、結果的に生まれた損失関数やネットワーク構造からでも、十分何が起きているのか理解できたかと思います。

ここまで読んだ上で、これがどのように変分ベイズ推定に基づいているのか興味が湧いた方は、そこを深掘っている記事を読みあさっていただければと思います。

## 特に参考にしたサイト
- [Variational Autoencoder徹底解説](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)
- [VAEって結局何者なの？](https://zenn.dev/asap/articles/6caa9043276424#vae（variational-auto-encoder）)
- 画像資料の一部は生成AIを用いています
