---
title: "【初学者向け】変分ベイズがわからずともVAEの大枠は掴める"
emoji: "😭"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: []
published: false
---

## 本記事の狙い
生成モデル初学者向けです．VAE（Variational Auto-Encoder）の解説記事を読んでも、式変形ばかりで結局何をしてるのかよくわからない...という人に向けています
- VAEが大まかに何をするか、から解説します
- ネットワーク構造、損失関数など、機械学習のよくあるアプローチで紹介します
- VAEの由来、変分ベイズ推定の話は詳しく解説しません

## VAEとは
- 画像などを生成できる，生成モデルです．
- **入力データから本質的な潜在変数を確率分布として推定（Encode）します。この分布から潜在変数をサンプリングして生成することで，多様な出力を生成できます（Decode）**
- 構造は以下の通りです．

## Auto Encoderとの違い
- Encoderでデータから潜在変数を学習し，Decoderで潜在変数からデータの再生成を試みるため，結果的にAuto Encoderの形になっています．AEは入力をそのまま再現することだけを考えますが、VAEは潜在変数$z$の分布が標準正規分布（など設定した事前分布）に近いと想定しながら、入力$X$に整合的な潜在空間$z$の**分布**を学習します

## 学習の流れ

ミニバッチごとに、以下の処理を繰り返している

1. **生成、そして損失計算**
    - 入力データ$X$をエンコーダに通し，潜在分布のパラメータ $μ_ϕ(X)$, $σ_ϕ(X)$を得る
    - $z=μ_ϕ(X)+σ_ϕ(X)ϵ \; (\,ϵ∼N(0,I)\,)$ をサンプリング（後述のreparametrization）
    - その$z$をデコーダに入れて再構築分布  $p_θ(X∣z)$を得る
    - 最大化したいELBO（再構成項−KL 項）を計算
2. **ネットワーク全体に誤差逆伝播**
    - この損失に対して $θ$（デコーダ側）と $ϕ$（エンコーダ側）の両方を同時に偏微分し，
    - SGD（あるいは Adam など）で両ネットワークのパラメータを一緒に更新

## 損失関数

- 次の値を**最大化**することを考える。**第一項が再構成項、第二項が正則化項**
    
    $$
    \text{ELBO} = \mathbb{E}_{q_\phi (z|X)}[\text{log}\,p_\theta (X|z)] - \text{KL}\bigl( q_\phi (z|X)|| p_{prior}(z) \bigr)
    $$
    
    **注意：ここの$p_\theta (\cdot)$と$p_{prior}(\cdot )$は全くの別物**。前者はデコーダNN、後者は潜在変数$z$の事前分布で標準正規分布$N(\bold0,\bold{I})$をよく使う。*両者別物の関数のくせに確率論の慣習で同じ$p$を使いやがる。なお$q$は、変分ベイズで登場する、真の分布の近似分布。*
    
- 第１項を大きくすることは、「出力の期待値が入力に近づく」こと。潜在空間からのデータ生成（デコーダ）の出力期待値を、入力データからの潜在空間推定（エンコーダ）に沿って計算してる
- 第２項のKLを小さく保つことは、「エンコーダの出力が事前分布に近づく」こと。過学習を防ぐ。
- もちろんこの２項のバランスはそう単純じゃないので、第二項に重みをつけたりする

## Reparametrization trick

- ニューラルネットの中に確率過程があるため、普通の誤差逆伝播ができない。ここで、VAEの構造を以下のように解釈することで、確率過程を外に出して、誤差逆伝播を可能にした。これをreparametrization trickと言う。（そんな突飛でもねえな）

## 損失関数の導出 - 変分ベイズ推定の部分

## 終わりに
VAEは実際のところ、変分ベイズ推定による潜在変数$z$の推定から誕生した手法です。ですがここまで見てきたように、結果的に生まれた損失関数やネットワーク構造からでも、十分何が起きているのか理解できたかと思います。

ここまで読んだ上で、これがどのように変分ベイズ推定に基づいているのか興味が湧いた方は、そこを深掘っている記事を読みあさっていただければと思います。

### 特に参考にしたサイト
- [Variational Autoencoder徹底解説](https://qiita.com/kenmatsu4/items/b029d697e9995d93aa24)
- [VAEって結局何者なの？](https://zenn.dev/asap/articles/6caa9043276424#vae（variational-auto-encoder）)
